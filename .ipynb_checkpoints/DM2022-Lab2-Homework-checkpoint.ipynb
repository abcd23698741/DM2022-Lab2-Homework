{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name:陳薇如\n",
    "\n",
    "Student ID: 110003816\n",
    "\n",
    "GitHub ID: abcd23698741\n",
    "\n",
    "Kaggle name: WJuChen (wjuchen)\n",
    "\n",
    "Kaggle private scoreboard snapshot: 29\n",
    "\n",
    "[Snapshot](img/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the [DM2022-Lab2-master Repo](https://github.com/keziatamus/DM2022-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm2022-isa5810-lab2-homework) regarding Emotion Recognition on Twitter by this link https://www.kaggle.com/t/2b0d14a829f340bc88d2660dc602d4bd. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (60-x)/6 + 20 points, where x is your ranking in the leaderboard (ie. If you rank 3rd your score will be (60-3)/6 + 20 = 29.5% out of 30%)   \n",
    "    Submit your last submission __BEFORE the deadline (Nov. 22th 11:59 pm, Tuesday)_. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 25th 11:59 pm, Friday)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Begin Assignment Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section1: take home\n",
    "Full version please check this repository: https://github.com/abcd23698741/DM2022-Lab2-Master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section2: kaggle competition\n",
    "Rank:29\n",
    "![rank](./img/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section3: kaggle model report\n",
    "### >> <span style=\"color:blue\"> Full version please check this notebook: </span>\n",
    "### >> <span style=\"color:blue\">Key steps are listed below, same content was also written in notebook.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1 Data preproceesing\n",
    "\n",
    "[illustration](img/pic1.png)\n",
    "![Data preprocessing](./img/pic1.png)\n",
    "\n",
    "#### Data source:\n",
    "- /kaggle/input/dm2022-isa5810-lab2-homework/tweets_DM.json\n",
    "- /kaggle/input/dm2022-isa5810-lab2-homework/data_identification.csv\n",
    "- /kaggle/input/dm2022-isa5810-lab2-homework/emotion.csv\n",
    "\n",
    "#### Steps:\n",
    "1. Read tweets_DM.json and use json_normalize to transform content in '_source' into dataframe. Constains 'tweet_id'.\n",
    "2. Read emotion.csv to get corresponding label(emotion). Join text by 'tweet_id'.\n",
    "3. Read data_identification.csv to get train/test label. Join text by 'tweet_id'.\n",
    "4. Apply data preprocessing function(code by myself) to clean up raw tweets.\n",
    "5. Split into training and validation dataset.\n",
    "\n",
    "#### Preprocess Func:\n",
    "1. demojize emoji into text\n",
    "2. Remove user (start from @)\n",
    "3. Replace website as 'https'\n",
    "4. Remove symbol\n",
    "5. Lower case\n",
    "\n",
    "example\n",
    "![example](./img/pic2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2 Feature engineering\n",
    "\n",
    "1. Downlaod pre-trained W2V model \"glove-twitter-25\" (length:25)\n",
    "2. Tokenize by apply tokenizer from tensorflow \n",
    "3. Withing W2V model and tokenizer can create embedding matrix\n",
    "4. pad_sequences from tensorflow (truncating='post', maxlen=40, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2 Model summary\n",
    "\n",
    "- Construct a model with LSTM.\n",
    "- Loss: 'sparse_categorical_crossentropy'\n",
    "- Apply early stop(Criteria: val_accuracy patience=2)\n",
    "\n",
    "![model](./img/model_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3 training report and explaination\n",
    "\n",
    "![loss_plot](./img/pic4.png)\n",
    "\n",
    "The model converged at the early stage. While the training accuracy keep raising, the enhancement of validation accuracy was slowing down even decreasing. The final training accuracy is higher than validation accuracy, which means the model is a little bit overfitting. As for the final prediction, the model didn't fit as well as training and validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4 Some Finding\n",
    "\n",
    "#### Data imbalance issue\n",
    "The dataset is highly imbalance. Therefore, the model tend to guess the majority class, such as 'joy', 'anticipation' and 'trust'. \n",
    "\n",
    "![class](./img/pic5.png)\n",
    "\n",
    "#### Ambiguous sentiment\n",
    "There are 8 type of emotions, which are: 'fear', 'surprise', 'sadness', 'disgust', 'joy', 'anger', 'anticipation', 'trust'. Some classes are really easy to mess up with each other, for example: 'joy' and 'anticipation'.\n",
    "\n",
    "#### Irony expression\n",
    "People sometimes use irony expression or emoji which may interfere the model.\n",
    "\n",
    "#### w2v model\n",
    "The performance of using w2v model is better than not using. But the improvement is not that much. Maybe the fundamental is to leverage on more powerful model like BERT, extract the latent feature than train a model. Actually, I have tried to use pretrained BERT model on huggingface, but the result is bad. The loss nearly no change during training process.  The model only predict the majority class. Therefore, I chose LSTM to do the final implement.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggestion\n",
    "\n",
    "It would be nice if spend some time let the top ranking students to share their model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
